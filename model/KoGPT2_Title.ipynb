{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KoGPT2_Title.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIwa4f0rU_TD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "de743c7c-5ddc-4e55-8ccc-6910e1d03d62"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnAN6wQhV8Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/TMI/KoGPT2\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgFiKU6VWGwX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a15537b4-b5fd-4089-f25c-3e09109787f3"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/f5/d79b5b40735086ff1100c680703e0f3efc830fa455e268e9e96f3c857e93/mxnet-1.6.0-py2.py3-none-any.whl (68.7MB)\n",
            "\u001b[K     |████████████████████████████████| 68.7MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.41.1)\n",
            "Collecting gluonnlp==0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/29/c7dffbfc39f8dd8bb9314df7aaf92a67f6c7826ed35d546c8fa63d6e5925/gluonnlp-0.8.3.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 41.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/7f/a5fae1ff61d427801e8845e6c1a3ee1c13db6c187e155ae58a0224f21a38/sentencepiece-0.1.6-cp36-cp36m-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 35.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.6.0+cu101)\n",
            "Collecting transformers==2.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 37.1MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 42.2MB/s \n",
            "\u001b[?25hCollecting dropbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/97/c5b2dbf6caf2dc644cb2ddc92417faba0616b4cd30777041e089fab92b81/dropbox-10.3.1-py3-none-any.whl (668kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet==1.6.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet==1.6.0->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->-r requirements.txt (line 5)) (0.16.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1->-r requirements.txt (line 6)) (1.14.47)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1->-r requirements.txt (line 6)) (2019.12.20)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r requirements.txt (line 7)) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet==1.6.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1->-r requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.1->-r requirements.txt (line 6)) (1.17.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.1->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.1->-r requirements.txt (line 6)) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX->-r requirements.txt (line 7)) (49.6.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.47->boto3->transformers==2.1.1->-r requirements.txt (line 6)) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.47->boto3->transformers==2.1.1->-r requirements.txt (line 6)) (2.8.1)\n",
            "Building wheels for collected packages: gluonnlp, sacremoses\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.8.3-cp36-none-any.whl size=293541 sha256=50dff8c53d86cb4c97ff7a0ae2cf9c1c18420f34071bfe09df7fd313400454c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/6e/32/521aa84da7f9ee725d3c9be0b5e0d771df659bf25da5929f6c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a4505544c7c75f1d0f4a8c1379d94769b0edc417ffce1840f257a0ba35087278\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built gluonnlp sacremoses\n",
            "Installing collected packages: graphviz, mxnet, gluonnlp, sentencepiece, sacremoses, transformers, tensorboardX, dropbox\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed dropbox-10.3.1 gluonnlp-0.8.3 graphviz-0.8.4 mxnet-1.6.0 sacremoses-0.0.43 sentencepiece-0.1.6 tensorboardX-2.1 transformers-2.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA3PGZ0TkUGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "809aab93-36d6-4dcf-cbf0-eea410ce8693"
      },
      "source": [
        "import argparse\n",
        "import re\n",
        "import subprocess\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gluonnlp\n",
        "import torch\n",
        "from gluonnlp.data import SentencepieceTokenizer \n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "from kogpt2.model.sample import sample_sequence\n",
        "from kogpt2.model.torch_gpt2 import GPT2Config, GPT2LMHeadModel\n",
        "from kogpt2.utils import download, get_tokenizer, tokenizer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
            "  Optimizer.opt_registry[name].__name__))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnBdTTnyCiTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pytorch_kogpt2 = {\n",
        "\t'url':\n",
        "\t'https://kobert.blob.core.windows.net/models/kogpt2/pytorch/pytorch_kogpt2_676e9bcfa7.params',\n",
        "\t'fname': 'pytorch_kogpt2_676e9bcfa7.params',\n",
        "\t'chksum': '676e9bcfa7'\n",
        "}\n",
        "\n",
        "kogpt2_config = {\n",
        "\t\"initializer_range\": 0.02,\n",
        "\t\"layer_norm_epsilon\": 1e-05,\n",
        "\t\"n_ctx\": 1024,\n",
        "\t\"n_embd\": 768,\n",
        "\t\"n_head\": 12,\n",
        "\t\"n_layer\": 12,\n",
        "\t\"n_positions\": 1024,\n",
        "\t\"vocab_size\": 50000,\n",
        "  \"output_past\": None\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht-bNABBqF_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Read_Dataset(Dataset):\n",
        "\n",
        "\tdef __init__(self, file_path,vocab,tokenizer):\n",
        "\t\tself.file_path = file_path\n",
        "\t\tself.data =[]\n",
        "\t\tself.vocab =vocab\n",
        "\t\tself.tokenizer = tokenizer\n",
        "\t\tfile = open(self.file_path, 'r', encoding='utf-8')\n",
        "\n",
        "\t\tdf = pd.read_csv(self.file_path)\n",
        "\n",
        "\t\tdatasets = []\n",
        "\t\tfor _, row in df.iterrows():\n",
        "\t\t\tdatasets.append([row[\"제목\"]])\n",
        "\t\t\t\n",
        "\t\tprint(\"tokenizer ending\")\n",
        "\t\tfor line in datasets:\n",
        "\t\t\tif not line[0]:\n",
        "\t\t\t\tbreak\n",
        "\t\t\tif len(line[0]) > 1024:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\telif len(line[0]) < 3:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ttokenized_line = tokenizer(line[0][:-1])\n",
        "\n",
        "\t\t\tindex_of_words = [vocab[vocab.bos_token], ] + vocab[tokenized_line] + [vocab[vocab.eos_token]]\n",
        "\n",
        "\t\t\tif len(index_of_words) < 3:\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\tself.data.append([index_of_words])\n",
        "\n",
        "\t\tprint(np.shape(self.data))\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\titem = self.data[index]\n",
        "\t\treturn item\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dBG5n5RX7aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def auto_enter(text):\n",
        "\ttext = (text.replace(\"   \", \"\\n\"))\n",
        "\ttext = text.split(\"\\n\")\n",
        "\n",
        "\ttext = [t.lstrip() for t in text if t != '']\n",
        "\treturn \"\\n\\n\".join(text)\n",
        "\n",
        "\n",
        "def main(epoch, save_path, load_path, samples, data_file_path, batch_size):\n",
        "\tctx = 'cuda'\n",
        "\tcachedir = '~/kogpt2/'\n",
        "\n",
        "\tsummary = SummaryWriter()\n",
        "\n",
        "\tmodel_info = pytorch_kogpt2\n",
        "\tmodel_path = download(model_info['url'],\n",
        "\t\t\t\t\t\t   model_info['fname'],\n",
        "\t\t\t\t\t\t   model_info['chksum'],\n",
        "\t\t\t\t\t\t   cachedir=cachedir)\n",
        " \n",
        "\tvocab_info = tokenizer\n",
        "\tvocab_path = download(vocab_info['url'],\n",
        "\t\t\t\t\t\t   vocab_info['fname'],\n",
        "\t\t\t\t\t\t   vocab_info['chksum'],\n",
        "\t\t\t\t\t\t   cachedir=cachedir)\n",
        "\n",
        "\tkogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n",
        "\n",
        "\tkogpt2model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "\tdevice = torch.device(ctx)\n",
        "\tkogpt2model.to(device)\n",
        "\n",
        "\ttry:\n",
        "\t\tcheckpoint = torch.load(load_path, map_location=device)\n",
        "\n",
        "\t\tkogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n",
        "\t\tkogpt2model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\t\tkogpt2model.eval()\n",
        "\texcept:\n",
        "\t\tcount = 0\n",
        "\telse:\n",
        "\t\tcount = int(re.findall(\"\\d+\", load_path)[2])\n",
        "\n",
        "\tprint(count)\n",
        " \n",
        "\tkogpt2model.train()\n",
        "\tvocab_b_obj = gluonnlp.vocab.BERTVocab.from_sentencepiece(vocab_path,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t mask_token=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t sep_token=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t cls_token=None,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t unknown_token='<unk>',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t padding_token='<pad>',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t bos_token='<s>',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t eos_token='</s>')\n",
        "\n",
        "\n",
        "\ttok_path = get_tokenizer()\n",
        "\tmodel, vocab = kogpt2model, vocab_b_obj\n",
        "\ttok = SentencepieceTokenizer(tok_path)\n",
        "\n",
        "\tdataset = Read_Dataset(data_file_path, vocab, tok)\n",
        "\tprint(\"Read_Dataset ok\")\n",
        "\tdata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "\n",
        "\n",
        "\n",
        "\tlearning_rate = 3e-5\n",
        "\tcriterion = torch.nn.CrossEntropyLoss()\n",
        "\toptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\tprint('KoGPT-2 Transfer Learning Start')\n",
        "\tavg_loss = (0.0, 0.0)\n",
        "\n",
        "\tfor epoch in range(epoch):\n",
        "\t\tfor data in data_loader:\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\tdata = torch.stack(data[0])\n",
        "\t\t\tdata = data.transpose(1,0)\n",
        "\t\t\tdata = data.to(ctx)\n",
        "\t\t\tmodel = model.to(ctx)\n",
        "\n",
        "\t\t\toutputs = model(data, labels=data)\n",
        "\t\t\tloss, logits = outputs[:2]\n",
        "\t\t\tloss = loss.to(ctx)\n",
        "\t\t\tloss.backward()\n",
        "\t\t\tavg_loss = (avg_loss[0] * 0.99 + loss, avg_loss[1] * 0.99 + 1.0)\n",
        "\t\t\toptimizer.step()\n",
        "\t\t\tif count % 10000 == 0:\n",
        "\t\t\t\tprint('epoch no.{0} train no.{1}  loss = {2:.5f} avg_loss = {3:.5f}' . format(epoch, count, loss, avg_loss[0] / avg_loss[1]))\n",
        "\t\t\t\tsummary.add_scalar('loss/avg_loss', avg_loss[0] / avg_loss[1], count)\n",
        "\t\t\t\tsummary.add_scalar('loss/loss', loss, count)\n",
        "\n",
        "\n",
        "\t\t\tif (count > 0 and count % 10000 == 0) or (len(data) < batch_size):\n",
        "\t\t\t\tsent = sample_sequence(model.to(\"cpu\"), tok, vocab, sent=\"역량\", text_size=100, temperature=0.7, top_p=0.8, top_k=40)\n",
        "\t\t\t\tsent = sent.replace(\"<unused0>\", \"\\n\")\n",
        "\t\t\t\tsent = auto_enter(sent)\n",
        "\t\t\t\tprint(sent)\n",
        "\n",
        "\t\t\t\tsummary.add_text('Text', sent, count)\n",
        "\n",
        "\t\t\t\tif count > 100000:\n",
        "\t\t\t\t\tnow = [int(n) for n in os.listdir(samples)]\n",
        "\t\t\t\t\tnow = max(now)\n",
        "\t\t\t\t\tf = open(samples + str(now + 1), 'w', encoding=\"utf-8\")\n",
        "\t\t\t\t\tf.write(sent)\n",
        "\t\t\t\t\tf.close()\n",
        "\t\t \n",
        "\t\t\tcount += 1\n",
        "\n",
        "\t\t\tif (count > 0 and count % 10000 == 0) or (len(data) < batch_size):\n",
        "\t\t\t\t\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\ttorch.save({\n",
        "\t\t\t\t\t\t'epoch': epoch,\n",
        "\t\t\t\t\t\t'train_no': count,\n",
        "\t\t\t\t\t\t'model_state_dict': model.state_dict(),\n",
        "\t\t\t\t\t\t'optimizer_state_dict': optimizer.state_dict(),\n",
        "\t\t\t\t\t\t'loss': loss\n",
        "\t\t\t\t\t}, save_path + 'KoGPT2_title_checkpoint_' + str(count) + '.tar')\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tpass"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VbGBKFnaDwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/TMI\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phz88YPwbITI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "0815a2d4-2fa3-49ca-9ca3-0eb35806f4c0"
      },
      "source": [
        "import pandas as pd\n",
        "from preprocess import _preprocess_qna\n",
        "\n",
        "df = pd.read_csv(\"jobkorea_all.csv\")\n",
        "df = _preprocess_qna(df)\n",
        "df = df.loc[:, \"제목\"]\n",
        "df.dropna().to_csv(\"dataset.txt\", index=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TMI/preprocess.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text[text.notna()] = text[text.notna()].apply(lambda x: re.sub(pattern, patterns[pattern], x))\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:8765: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._update_inplace(new_data)\n",
            "/content/drive/My Drive/TMI/preprocess.py:99: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\\}.*\": \"\"\n",
            "/content/drive/My Drive/TMI/preprocess.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text[text.notna()] = text[text.notna()].apply(lambda x: re.sub(pattern, replacement, x))\n",
            "/content/drive/My Drive/TMI/preprocess.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text[text.notna()] = text[text.notna()].apply(lambda x: re.sub(\"\\s+\", replacement, x))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M__ybw6R8Ud0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c1599284-2180-4d8a-8641-ebac838f0cb6"
      },
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKOVsTtX6caR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "8fb53c93-a6e2-4277-c55a-14de776a55c2"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 26 05:44:36 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P0    73W / 149W |    432MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXDB8a6pf3O0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "1877df18-e02c-4b30-de61-bbbac451064d"
      },
      "source": [
        "main(epoch=10,\n",
        "     save_path=\"/content/drive/My Drive/TMI/KoGPT2/\",\n",
        "     load_path=\"/content/drive/My Drive/TMI/KoGPT2/KoGPT2_title_checkpoint_30000.tar\",\n",
        "     samples=\"/content/drive/My Drive/TMI/KoGPT2/\",\n",
        "     data_file_path=\"dataset.txt\",\n",
        "     batch_size=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n",
            "30000\n",
            "using cached model\n",
            "tokenizer ending\n",
            "(13528, 1)\n",
            "Read_Dataset ok\n",
            "KoGPT-2 Transfer Learning Start\n",
            "epoch no.0 train no.30000  loss = 4.41747 avg_loss = 4.41747\n",
            "2\n",
            "to_tokens: ['▁\"', '개발을', '▁엔', '</s>']\n",
            "역량 있는 인</s>\n",
            "epoch no.0 train no.40000  loss = 4.71435 avg_loss = 3.52046\n",
            "7\n",
            "to_tokens: ['▁\"', '개발을', '▁위한', '▁노', ',', '▁그리고', '▁성취', '</s>', '</s>']\n",
            "역량개발을 위한 노력, 그리고 성과달</s>\n",
            "epoch no.1 train no.50000  loss = 3.49887 avg_loss = 2.98632\n",
            "3\n",
            "to_tokens: ['▁\"', '개발을', '▁위한', '▁역량', '</s>']\n",
            "역량 강화를 위한 노</s>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}